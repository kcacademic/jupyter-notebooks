{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def convert_y_to_vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def f_deriv(x):\n",
    "    return f(x) * (1 - f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as r\n",
    "def setup_and_init_weights(nn_structure):\n",
    "    W = {}\n",
    "    b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        W[l] = r.random_sample((nn_structure[l], nn_structure[l-1]))\n",
    "        b[l] = r.random_sample((nn_structure[l],))\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_tri_values(nn_structure):\n",
    "    tri_W = {}\n",
    "    tri_b = {}\n",
    "    for l in range(1, len(nn_structure)):\n",
    "        tri_W[l] = np.zeros((nn_structure[l], nn_structure[l-1]))\n",
    "        tri_b[l] = np.zeros((nn_structure[l],))\n",
    "    return tri_W, tri_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(x, W, b):\n",
    "    h = {1: x}\n",
    "    z = {}\n",
    "    for l in range(1, len(W) + 1):\n",
    "        # if it is the first layer, then the input into the weights is x, otherwise, \n",
    "        # it is the output from the last layer\n",
    "        if l == 1:\n",
    "            node_in = x\n",
    "        else:\n",
    "            node_in = h[l]\n",
    "        z[l+1] = W[l].dot(node_in) + b[l] # z^(l+1) = W^(l)*h^(l) + b^(l)  \n",
    "        h[l+1] = f(z[l+1]) # h^(l) = f(z^(l)) \n",
    "    return h, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_out_layer_delta(y, h_out, z_out):\n",
    "    # delta^(nl) = -(y_i - h_i^(nl)) * f'(z_i^(nl))\n",
    "    return -(y-h_out) * f_deriv(z_out)\n",
    "\n",
    "def calculate_hidden_delta(delta_plus_1, w_l, z_l):\n",
    "    # delta^(l) = (transpose(W^(l)) * delta^(l+1)) * f'(z^(l))\n",
    "    return np.dot(np.transpose(w_l), delta_plus_1) * f_deriv(z_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(nn_structure, X, y, iter_num=3000, alpha=0.25):\n",
    "    W, b = setup_and_init_weights(nn_structure)\n",
    "    cnt = 0\n",
    "    m = len(y)\n",
    "    avg_cost_func = []\n",
    "    print('Starting gradient descent for {} iterations'.format(iter_num))\n",
    "    while cnt < iter_num:\n",
    "        if cnt%1000 == 0:\n",
    "            print('Iteration {} of {}'.format(cnt, iter_num))\n",
    "        tri_W, tri_b = init_tri_values(nn_structure)\n",
    "        avg_cost = 0\n",
    "        for i in range(len(y)):\n",
    "            delta = {}\n",
    "            # perform the feed forward pass and return the stored h and z values, to be used in the\n",
    "            # gradient descent step\n",
    "            h, z = feed_forward(X[i, :], W, b)\n",
    "            # loop from nl-1 to 1 backpropagating the errors\n",
    "            for l in range(len(nn_structure), 0, -1):\n",
    "                if l == len(nn_structure):\n",
    "                    delta[l] = calculate_out_layer_delta(y[i,:], h[l], z[l])\n",
    "                    avg_cost += np.linalg.norm((y[i,:]-h[l]))\n",
    "                else:\n",
    "                    if l > 1:\n",
    "                        delta[l] = calculate_hidden_delta(delta[l+1], W[l], z[l])\n",
    "                    # triW^(l) = triW^(l) + delta^(l+1) * transpose(h^(l))\n",
    "                    tri_W[l] += np.dot(delta[l+1][:,np.newaxis], np.transpose(h[l][:,np.newaxis])) \n",
    "                    # trib^(l) = trib^(l) + delta^(l+1)\n",
    "                    tri_b[l] += delta[l+1]\n",
    "        # perform the gradient descent step for the weights in each layer\n",
    "        for l in range(len(nn_structure) - 1, 0, -1):\n",
    "            W[l] += -alpha * (1.0/m * tri_W[l])\n",
    "            b[l] += -alpha * (1.0/m * tri_b[l])\n",
    "        # complete the average cost calculation\n",
    "        avg_cost = 1.0/m * avg_cost\n",
    "        avg_cost_func.append(avg_cost)\n",
    "        cnt += 1\n",
    "    return W, b, avg_cost_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(W, b, X, n_layers):\n",
    "    m = X.shape[0]\n",
    "    y = np.zeros((m,))\n",
    "    for i in range(m):\n",
    "        h, z = feed_forward(X[i, :], W, b)\n",
    "        y[i] = np.argmax(h[n_layers])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALpklEQVR4nO3d/2td9R3H8ddraYvfaiPTiVixE2ZBhCVFyqSg/aJSp7S/7IcWFCYb3Q+bGDYQ3S/Vf0DcD0MoVStYK1otHbI5CxpE2HT9Emc1dWipmFaNYtOqgxX1vR/uqWRdtpzE8zm5yfv5gEvuvbk573cSXvdzzrnnnI8jQgDmtu/MdAMAyiPoQAIEHUiAoAMJEHQgAYIOJNAVQbe91vbbtt+xfU/hWo/YHrV9sGSdcfUus/2S7WHbb9q+q3C9s2y/Zvv1qt79JetVNXtsH7D9XOlaVb0jtt+wPWR7b+FavbZ32j5U/Q+vLVhrafU7nb6dtD3QyMIjYkZvknokvSvpCkkLJL0u6aqC9a6TtEzSwZZ+v0skLavuL5T0j8K/nyWdV92fL+lVST8q/Dv+WtITkp5r6W96RNKFLdV6TNLPq/sLJPW2VLdH0oeSLm9ied0woi+X9E5EHI6IU5KelLS+VLGIeFnSp6WWP0G9DyJif3X/M0nDki4tWC8i4vPq4fzqVuyoKNuLJd0iaWupGjPF9vnqDAwPS1JEnIqIsZbKr5H0bkS818TCuiHol0p6f9zjERUMwkyyvURSvzqjbMk6PbaHJI1K2hMRJes9KOluSV8XrHGmkPSC7X22NxWsc4WkjyU9Wm2abLV9bsF6422QtKOphXVD0D3Bc3PuuFzb50l6RtJARJwsWSsivoqIPkmLJS23fXWJOrZvlTQaEftKLP//WBERyyTdLOmXtq8rVGeeOpt5D0VEv6QvJBXdhyRJthdIWifp6aaW2Q1BH5F02bjHiyUdm6FeirA9X52Qb4+IZ9uqW61mDkpaW6jECknrbB9RZ5Nrte3HC9X6RkQcq76OStqlzuZfCSOSRsatEe1UJ/il3Sxpf0R81NQCuyHof5P0A9vfr97JNkj6wwz31BjbVmcbbzgiHmih3kW2e6v7Z0u6QdKhErUi4t6IWBwRS9T5v70YEbeVqHWa7XNtLzx9X9JNkop8ghIRH0p63/bS6qk1kt4qUesMG9XgarvUWTWZURHxpe1fSfqzOnsaH4mIN0vVs71D0kpJF9oekbQ5Ih4uVU+dUe92SW9U282S9NuI+GOhepdIesx2jzpv5E9FRCsfe7XkYkm7Ou+fmifpiYh4vmC9OyVtrwahw5LuKFhLts+RdKOkXzS63GpXPoA5rBtW3QEURtCBBAg6kABBBxIg6EACXRX0woczzlgt6lFvput1VdAltfnHbPUfRz3qzWS9bgs6gAKKHDBjm6NwGnTllVdO+WdOnDihRYsWTavevHlTP2Dy+PHjuuCCC6ZV7+jRo1P+mVOnTmnBggXTqnfixIlp/dxsERH/daIYQZ8FBgcHW63X29vbar3Nmze3Wm/37t2t1mvbREFn1R1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAK1gt7mlEkAmjdp0KuLDP5enUvQXiVpo+2rSjcGoDl1RvRWp0wC0Lw6QU8zZRIwV9U5TanWlEnVifJtn7MLoIY6Qa81ZVJEbJG0ReLsNaDb1Fl1n9NTJgEZTDqitz1lEoDm1bqUSDVPWKm5wgAUxpFxQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSmPrcO2jd2NhYq/Wuv/76VuutWrWq1XpzfaaWiTCiAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IIE6UzI9YnvU9sE2GgLQvDoj+jZJawv3AaCgSYMeES9L+rSFXgAUwjY6kEBjp6ky9xrQvRoLOnOvAd2LVXcggTofr+2Q9BdJS22P2P5Z+bYANKnOJIsb22gEQDmsugMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSIC516ahr6+v1XorV65stV7bhoaGZrqFOY8RHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwnUuTjkZbZfsj1s+03bd7XRGIDm1DnW/UtJv4mI/bYXStpne09EvFW4NwANqTP32gcRsb+6/5mkYUmXlm4MQHOmtI1ue4mkfkmvlmgGQBm1T1O1fZ6kZyQNRMTJCb7P3GtAl6oVdNvz1Qn59oh4dqLXMPca0L3q7HW3pIclDUfEA+VbAtC0OtvoKyTdLmm17aHq9uPCfQFoUJ25116R5BZ6AVAIR8YBCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUhgTsy9NjAw0Gq9++67r9V6ixYtarVe2wYHB2e6hTmPER1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAIEHUiAoAMJ1LkK7Fm2X7P9ejX32v1tNAagOXWOdf+XpNUR8Xl1ffdXbP8pIv5auDcADalzFdiQ9Hn1cH51Y4IGYBaptY1uu8f2kKRRSXsigrnXgFmkVtAj4quI6JO0WNJy21ef+Rrbm2zvtb236SYBfDtT2useEWOSBiWtneB7WyLimoi4pqHeADSkzl73i2z3VvfPlnSDpEOlGwPQnDp73S+R9JjtHnXeGJ6KiOfKtgWgSXX2uv9dUn8LvQAohCPjgAQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4k4M5ZqA0v1J7Tp7H29va2Wu/48eOt1mtbf3+7x2MNDQ21Wq9tEeEzn2NEBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQAEEHEiDoQAK1g15N4nDANheGBGaZqYzod0kaLtUIgHLqTsm0WNItkraWbQdACXVH9Acl3S3p64K9ACikzkwtt0oajYh9k7yOudeALlVnRF8haZ3tI5KelLTa9uNnvoi514DuNWnQI+LeiFgcEUskbZD0YkTcVrwzAI3hc3QggTqTLH4jIgbVmTYZwCzCiA4kQNCBBAg6kABBBxIg6EACBB1IgKADCRB0IIEpHTADlNDX19dqvbk+99pEGNGBBAg6kABBBxIg6EACBB1IgKADCRB0IAGCDiRA0IEECDqQQK1DYKtLPX8m6StJX3JJZ2B2mcqx7qsi4pNinQAohlV3IIG6QQ9JL9jeZ3tTyYYANK/uqvuKiDhm+3uS9tg+FBEvj39B9QbAmwDQhWqN6BFxrPo6KmmXpOUTvIa514AuVWc21XNtLzx9X9JNkg6WbgxAc+qsul8saZft069/IiKeL9oVgEZNGvSIOCzphy30AqAQPl4DEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACBB1IoFbQbffa3mn7kO1h29eWbgxAc+pO4PA7Sc9HxE9sL5B0TsGeADRs0qDbPl/SdZJ+KkkRcUrSqbJtAWhSnVX3KyR9LOlR2wdsb60mcvgPtjfZ3mt7b+NdAvhW6gR9nqRlkh6KiH5JX0i658wXMSUT0L3qBH1E0khEvFo93qlO8AHMEpMGPSI+lPS+7aXVU2skvVW0KwCNqrvX/U5J26s97ocl3VGuJQBNqxX0iBiSxLY3MEtxZByQAEEHEiDoQAIEHUiAoAMJEHQgAYIOJEDQgQTqHhmHccbGxlqtt3v37lbrrV+/vtV6K1eubLXetm3bWq3XDRjRgQQIOpAAQQcSIOhAAgQdSICgAwkQdCABgg4kQNCBBCYNuu2ltofG3U7aHmijOQDNmPQQ2Ih4W1KfJNnukXRU0q7CfQFo0FRX3ddIejci3ivRDIAyphr0DZJ2lGgEQDm1g15d032dpKf/x/eZew3oUlM5TfVmSfsj4qOJvhkRWyRtkSTb0UBvABoylVX3jWK1HZiVagXd9jmSbpT0bNl2AJRQd0qmf0r6buFeABTCkXFAAgQdSICgAwkQdCABgg4kQNCBBAg6kABBBxIg6EACjmj+/BPbH0uazjnrF0r6pOF2uqEW9ajXVr3LI+KiM58sEvTpsr03Iq6Za7WoR72ZrseqO5AAQQcS6Lagb5mjtahHvRmt11Xb6ADK6LYRHUABBB1IgKADCRB0IAGCDiTwbwuQdvD/0C3PAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(digits.images[1]) \n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_scale = StandardScaler()\n",
    "X = X_scale.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = digits.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_v_train = convert_y_to_vect(y_train)\n",
    "y_v_test = convert_y_to_vect(y_test)\n",
    "y_train[0], y_v_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_structure = [64, 30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting gradient descent for 3000 iterations\n",
      "Iteration 0 of 3000\n"
     ]
    }
   ],
   "source": [
    "W, b, avg_cost_func = train_nn(nn_structure, X_train, y_v_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_cost_func)\n",
    "plt.ylabel('Average J')\n",
    "plt.xlabel('Iteration number')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = predict_y(W, b, X_test, 3)\n",
    "accuracy_score(y_test, y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
